{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092512bb",
   "metadata": {},
   "source": [
    "### Импортирую pandas для извлечения датасетов\n",
    "Создаю переменную tweets, где будут только позитивные и отрицательные сообщения (без имен пользователя и тд)\\\n",
    "Вывожу хвост из 3 данных, чтобы убедиться, что в переменной все твиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c606e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>@_music_lover_13 оооо, еще и Оля) какая прелес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>@GazetaRu_All Ныне картина того,как у ЕС,сжало...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>RT @bazzzilio: @VRSoloviev :)) Я все еще жив, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      neg   \n",
       "111920          Вот и в школу, в говно это идти уже надо(  \\\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...   \n",
       "111922  Такси везет меня на работу. Раздумываю приплат...   \n",
       "\n",
       "                                                      pos  \n",
       "111920  @_music_lover_13 оооо, еще и Оля) какая прелес...  \n",
       "111921  @GazetaRu_All Ныне картина того,как у ЕС,сжало...  \n",
       "111922  RT @bazzzilio: @VRSoloviev :)) Я все еще жив, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets_neg = pd.read_csv('negative.csv', delimiter=';', \n",
    "                    names=['none1', 'none2', 'none3', 'text', 'none4', 'none5', \n",
    "                           'none6', 'none7', 'none8', 'none9', 'none10', 'none11'])\n",
    "tweets_pos = pd.read_csv('positive.csv', delimiter=';', \n",
    "                    names=['none1', 'none2', 'none3', 'text', 'none4', 'none5', \n",
    "                           'none6', 'none7', 'none8', 'none9', 'none10', 'none11'])\n",
    "tweets = pd.DataFrame()\n",
    "tweets['neg'], tweets['pos'] = tweets_neg['text'], tweets_pos['text']\n",
    "tweets.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170d6b0",
   "metadata": {},
   "source": [
    "Загрузка русских стоп-слов с помощью библиотеки nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cacf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d652d6",
   "metadata": {},
   "source": [
    "Обрабатываю сообщения пользователей с помощью регулярных выражений и строки стоп-слов\n",
    "\n",
    "1. Из каждого сообщения оставляю только русские слова\n",
    "2. Делаю из строки массив слов, где разделитель на слова служит любое кол-во пробелов\n",
    "3. Создаю строку так, чтобы проверяемое слово не было стоп-словом и длина была не меньше 2 и нормализую его\n",
    "\n",
    "Функция norm_form запоминает все нормализованные слова, чтобы ускорить программу и каждый раз не запускать morpth.parse.\n",
    "Иначе программа работает в 8-10 раз медленее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4c050d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>negClean</th>\n",
       "      <th>posClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>работа полный пиддес каждый закрытие месяц сви...</td>\n",
       "      <td>школотый поверь самый общество профилировать п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>коллега сидеть рубиться долбать винд мочь</td>\n",
       "      <td>таки немного похожий мальчик равно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>говорить обещаной год ждать</td>\n",
       "      <td>идиотка испугаться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>желать хороший пол удачный посадка быть очень ...</td>\n",
       "      <td>угол сидеть погибать голод порция взять хотя ж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>обновить какой леший работать простоплеер</td>\n",
       "      <td>значит страшилка блин посмотреть часть создать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Котёнка вчера носик разбила, плакала и расстра...</td>\n",
       "      <td>ну любишь или нет? — Я не знаю кто ты бля:D ht...</td>\n",
       "      <td>кот нка вчера носик разбить плакать расстраива...</td>\n",
       "      <td>любить знать бля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@juliamayko @O_nika55 @and_Possum Зашли, а то ...</td>\n",
       "      <td>RT @SpoonLamer: Ох,900 :D ну это конечно же @t...</td>\n",
       "      <td>заслать затихариться прямо физически страдать ...</td>\n",
       "      <td>это друг такой мимими</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>а вообще я не болею -  я не выздоравливаю :(</td>\n",
       "      <td>RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...</td>\n",
       "      <td>вообще болеть выздоравливать</td>\n",
       "      <td>ухаж мой ухо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>я микрофраза :( учимся срать кирпичами в режим...</td>\n",
       "      <td>Поприветствуем моего нового читателя @Alexey17...</td>\n",
       "      <td>микрофраза учиться срать кирпич режим нона стоп</td>\n",
       "      <td>поприветствовать мой новый читатель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>я хочу с тобой помириться , но сука я гордая и...</td>\n",
       "      <td>Теперь у меня есть частичка Сиднея :) #Sydney ...</td>\n",
       "      <td>хотеть ты помириться сука гордый сделать</td>\n",
       "      <td>частичка сидней</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 neg   \n",
       "0  на работе был полный пиддес :| и так каждое за...  \\\n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...   \n",
       "2  @elina_4post как говорят обещаного три года жд...   \n",
       "3  Желаю хорошего полёта и удачной посадки,я буду...   \n",
       "4  Обновил за каким-то лешим surf, теперь не рабо...   \n",
       "5  Котёнка вчера носик разбила, плакала и расстра...   \n",
       "6  @juliamayko @O_nika55 @and_Possum Зашли, а то ...   \n",
       "7       а вообще я не болею -  я не выздоравливаю :(   \n",
       "8  я микрофраза :( учимся срать кирпичами в режим...   \n",
       "9  я хочу с тобой помириться , но сука я гордая и...   \n",
       "\n",
       "                                                 pos   \n",
       "0  @first_timee хоть я и школота, но поверь, у на...  \\\n",
       "1  Да, все-таки он немного похож на него. Но мой ...   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...   \n",
       "5  ну любишь или нет? — Я не знаю кто ты бля:D ht...   \n",
       "6  RT @SpoonLamer: Ох,900 :D ну это конечно же @t...   \n",
       "7  RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...   \n",
       "8  Поприветствуем моего нового читателя @Alexey17...   \n",
       "9  Теперь у меня есть частичка Сиднея :) #Sydney ...   \n",
       "\n",
       "                                            negClean   \n",
       "0  работа полный пиддес каждый закрытие месяц сви...  \\\n",
       "1          коллега сидеть рубиться долбать винд мочь   \n",
       "2                        говорить обещаной год ждать   \n",
       "3  желать хороший пол удачный посадка быть очень ...   \n",
       "4          обновить какой леший работать простоплеер   \n",
       "5  кот нка вчера носик разбить плакать расстраива...   \n",
       "6  заслать затихариться прямо физически страдать ...   \n",
       "7                       вообще болеть выздоравливать   \n",
       "8    микрофраза учиться срать кирпич режим нона стоп   \n",
       "9           хотеть ты помириться сука гордый сделать   \n",
       "\n",
       "                                            posClean  \n",
       "0  школотый поверь самый общество профилировать п...  \n",
       "1                 таки немного похожий мальчик равно  \n",
       "2                                 идиотка испугаться  \n",
       "3  угол сидеть погибать голод порция взять хотя ж...  \n",
       "4  значит страшилка блин посмотреть часть создать...  \n",
       "5                                   любить знать бля  \n",
       "6                              это друг такой мимими  \n",
       "7                                       ухаж мой ухо  \n",
       "8                поприветствовать мой новый читатель  \n",
       "9                                    частичка сидней  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "\n",
    "norm = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def norm_form(word):\n",
    "    res = norm.get(word)\n",
    "    if res:\n",
    "        return res\n",
    "    res = morph.parse(word)[0].normal_form\n",
    "    norm[word] = res\n",
    "    return res\n",
    "\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "  tempArr = []\n",
    "  for tweet in tweets['neg']:\n",
    "    tweet = re.sub(r'[^а-яА-Я]', ' ', tweet.lower())\n",
    "    tweet = re.split(r'\\s+', tweet)\n",
    "    tweet = ' '.join([norm_form(word) for word in tweet if len(word) > 2 and word not in russian_stopwords])\n",
    "    tempArr.append(tweet)\n",
    "  tweets['negClean'] = pd.Series(tempArr)\n",
    "  \n",
    "  tempArr = []  \n",
    "  for tweet in tweets['pos']:\n",
    "    tweet = re.sub(r'[^а-яА-Я]', ' ', tweet.lower())\n",
    "    tweet = tweet.split()\n",
    "    tweet = ' '.join([norm_form(word) for word in tweet if len(word) > 2 and word not in russian_stopwords])\n",
    "    tempArr.append(tweet) \n",
    "  tweets['posClean'] = pd.Series(tempArr)\n",
    "\n",
    "  return tweets\n",
    "    \n",
    "\n",
    "tweets = clean_tweets(tweets)\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0dc929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "count_vector=cv.fit_transform(tweets['neg'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
