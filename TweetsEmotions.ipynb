{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092512bb",
   "metadata": {},
   "source": [
    "### Импортирую pandas для извлечения датасетов\n",
    "Создаю переменную tweets, где будут только позитивные и отрицательные сообщения (без имен пользователя и тд)\\\n",
    "Вывожу хвост из 3 данных, чтобы убедиться, что в переменной все твиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c606e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>@_music_lover_13 оооо, еще и Оля) какая прелес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>@GazetaRu_All Ныне картина того,как у ЕС,сжало...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>RT @bazzzilio: @VRSoloviev :)) Я все еще жив, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      neg   \n",
       "111920          Вот и в школу, в говно это идти уже надо(  \\\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...   \n",
       "111922  Такси везет меня на работу. Раздумываю приплат...   \n",
       "\n",
       "                                                      pos  \n",
       "111920  @_music_lover_13 оооо, еще и Оля) какая прелес...  \n",
       "111921  @GazetaRu_All Ныне картина того,как у ЕС,сжало...  \n",
       "111922  RT @bazzzilio: @VRSoloviev :)) Я все еще жив, ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets_neg = pd.read_csv('negative.csv', delimiter=';', \n",
    "                    names=['none1', 'none2', 'none3', 'text', 'none4', 'none5', \n",
    "                           'none6', 'none7', 'none8', 'none9', 'none10', 'none11'])\n",
    "tweets_pos = pd.read_csv('positive.csv', delimiter=';', \n",
    "                    names=['none1', 'none2', 'none3', 'text', 'none4', 'none5', \n",
    "                           'none6', 'none7', 'none8', 'none9', 'none10', 'none11'])\n",
    "tweets = pd.DataFrame()\n",
    "tweets['neg'], tweets['pos'] = tweets_neg['text'], tweets_pos['text']\n",
    "tweets.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170d6b0",
   "metadata": {},
   "source": [
    "Загрузка русских стоп-слов с помощью библиотеки nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cacf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d652d6",
   "metadata": {},
   "source": [
    "Обрабатываю сообщения пользователей с помощью регулярных выражений и строки стоп-слов\n",
    "\n",
    "1. Из каждого сообщения оставляю только русские слова и привожу к нижнему регистру\n",
    "2. Делаю из строки массив слов, где разделитель на слова служит любое кол-во пробелов\n",
    "3. Создаю строку так, чтобы проверяемое слово не было стоп-словом и длина была не меньше 2 и нормализую его\n",
    "\n",
    "Функция norm_word:  \n",
    "Для начала проверяю есть ли нужное слово в словаре со словами в начальной форме  \n",
    "Если есть, то возвращаю слово в начальной форму  \n",
    "Если нет, то с помощью библиотеки pymorphy2 и его анализатора, возвращаю слово в нормальной форме и запомнимаю его в словаре.    Возращаю результат  \n",
    "Зачем? Потому что если какждый раз вызывать анализатор pymorphy2, то это будет ОЧЕНЬ долго (я за 5 минут не смог дождаться), так как он каждый раз вызывает свой алгоритм и если одно и тоже слово появляется уже в 10 раз, то и время займет в 10 раз больше. А я буду запоминать значение и если попалось тоже слово, то выводить сразу его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674bb7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>negClean</th>\n",
       "      <th>posClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>работа полный пиддес каждый закрытие месяц сви...</td>\n",
       "      <td>школотый поверь самый общество профилировать п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>коллега сидеть рубиться долбать винд мочь</td>\n",
       "      <td>таки немного похожий мальчик равно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>говорить обещаной год ждать</td>\n",
       "      <td>идиотка испугаться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>желать хороший пол удачный посадка быть очень ...</td>\n",
       "      <td>угол сидеть погибать голод порция взять хотя ж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>обновить какой леший работать простоплеер</td>\n",
       "      <td>значит страшилка блин посмотреть часть создать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Котёнка вчера носик разбила, плакала и расстра...</td>\n",
       "      <td>ну любишь или нет? — Я не знаю кто ты бля:D ht...</td>\n",
       "      <td>кот нка вчера носик разбить плакать расстраива...</td>\n",
       "      <td>любить знать бля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@juliamayko @O_nika55 @and_Possum Зашли, а то ...</td>\n",
       "      <td>RT @SpoonLamer: Ох,900 :D ну это конечно же @t...</td>\n",
       "      <td>заслать затихариться прямо физически страдать ...</td>\n",
       "      <td>это друг такой мимими</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>а вообще я не болею -  я не выздоравливаю :(</td>\n",
       "      <td>RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...</td>\n",
       "      <td>вообще болеть выздоравливать</td>\n",
       "      <td>ухаж мой ухо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>я микрофраза :( учимся срать кирпичами в режим...</td>\n",
       "      <td>Поприветствуем моего нового читателя @Alexey17...</td>\n",
       "      <td>микрофраза учиться срать кирпич режим нона стоп</td>\n",
       "      <td>поприветствовать мой новый читатель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>я хочу с тобой помириться , но сука я гордая и...</td>\n",
       "      <td>Теперь у меня есть частичка Сиднея :) #Sydney ...</td>\n",
       "      <td>хотеть ты помириться сука гордый сделать</td>\n",
       "      <td>частичка сидней</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 neg   \n",
       "0  на работе был полный пиддес :| и так каждое за...  \\\n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...   \n",
       "2  @elina_4post как говорят обещаного три года жд...   \n",
       "3  Желаю хорошего полёта и удачной посадки,я буду...   \n",
       "4  Обновил за каким-то лешим surf, теперь не рабо...   \n",
       "5  Котёнка вчера носик разбила, плакала и расстра...   \n",
       "6  @juliamayko @O_nika55 @and_Possum Зашли, а то ...   \n",
       "7       а вообще я не болею -  я не выздоравливаю :(   \n",
       "8  я микрофраза :( учимся срать кирпичами в режим...   \n",
       "9  я хочу с тобой помириться , но сука я гордая и...   \n",
       "\n",
       "                                                 pos   \n",
       "0  @first_timee хоть я и школота, но поверь, у на...  \\\n",
       "1  Да, все-таки он немного похож на него. Но мой ...   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...   \n",
       "5  ну любишь или нет? — Я не знаю кто ты бля:D ht...   \n",
       "6  RT @SpoonLamer: Ох,900 :D ну это конечно же @t...   \n",
       "7  RT @veregijytaqo: У тебя есть ухажёр? Нет - мо...   \n",
       "8  Поприветствуем моего нового читателя @Alexey17...   \n",
       "9  Теперь у меня есть частичка Сиднея :) #Sydney ...   \n",
       "\n",
       "                                            negClean   \n",
       "0  работа полный пиддес каждый закрытие месяц сви...  \\\n",
       "1          коллега сидеть рубиться долбать винд мочь   \n",
       "2                        говорить обещаной год ждать   \n",
       "3  желать хороший пол удачный посадка быть очень ...   \n",
       "4          обновить какой леший работать простоплеер   \n",
       "5  кот нка вчера носик разбить плакать расстраива...   \n",
       "6  заслать затихариться прямо физически страдать ...   \n",
       "7                       вообще болеть выздоравливать   \n",
       "8    микрофраза учиться срать кирпич режим нона стоп   \n",
       "9           хотеть ты помириться сука гордый сделать   \n",
       "\n",
       "                                            posClean  \n",
       "0  школотый поверь самый общество профилировать п...  \n",
       "1                 таки немного похожий мальчик равно  \n",
       "2                                 идиотка испугаться  \n",
       "3  угол сидеть погибать голод порция взять хотя ж...  \n",
       "4  значит страшилка блин посмотреть часть создать...  \n",
       "5                                   любить знать бля  \n",
       "6                              это друг такой мимими  \n",
       "7                                       ухаж мой ухо  \n",
       "8                поприветствовать мой новый читатель  \n",
       "9                                    частичка сидней  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "\n",
    "norm = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def norm_form(word):\n",
    "    res = norm.get(word)\n",
    "    if res:\n",
    "        return res\n",
    "    res = morph.parse(word)[0].normal_form\n",
    "    norm[word] = res\n",
    "    return res\n",
    "\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "  tempArr = []\n",
    "  for tweet in tweets['neg']:\n",
    "    tweet = re.sub(r'[^а-яА-Я]', ' ', tweet.lower())\n",
    "    tweet = re.split(r'\\s+', tweet)\n",
    "    tweet = ' '.join([norm_form(word) for word in tweet if len(word) > 2 and word not in russian_stopwords])\n",
    "    tempArr.append(tweet)\n",
    "  tweets['negClean'] = pd.Series(tempArr)\n",
    "  \n",
    "  tempArr = []  \n",
    "  for tweet in tweets['pos']:\n",
    "    tweet = re.sub(r'[^а-яА-Я]', ' ', tweet.lower())\n",
    "    tweet = tweet.split()\n",
    "    tweet = ' '.join([norm_form(word) for word in tweet if len(word) > 2 and word not in russian_stopwords])\n",
    "    tempArr.append(tweet) \n",
    "  tweets['posClean'] = pd.Series(tempArr)\n",
    "\n",
    "  return tweets\n",
    "    \n",
    "\n",
    "tweets = clean_tweets(tweets)\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dfa95c",
   "metadata": {},
   "source": [
    "Обучающая и тестовая выборка\n",
    "\n",
    "Для позитивных твитов беру все значение y равным 1  \n",
    "Для отрицательных твитов равным 0  \n",
    "Таким образом делю выборку в пропорциях 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcdadc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pos_train, pos_test, y1_train, y1_test = train_test_split(tweets['posClean'], [1]*len(tweets['posClean']), test_size = 0.3)\n",
    "neg_train, neg_test, y2_train, y2_test = train_test_split(tweets['negClean'], [0]*len(tweets['negClean']), test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0dc929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(3, 3))\n",
    "\n",
    "pos_train = cv.fit_transform(pos_train).reshape(-1, 1)\n",
    "pos_test = cv.fit_transform(pos_test).reshape(-1, 1)\n",
    "neg_test = cv.fit_transform(neg_test).reshape(-1, 1)\n",
    "neg_train = cv.fit_transform(neg_train).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c009f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25442471770, 1) (78346, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25442471770, 78346]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(pos_train\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39marray(y1_train)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m metrics \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclassification_report\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y1_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(pos_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25442471770, 78346]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "print(pos_train.shape, np.array(y1_train).reshape(-1, 1).shape)\n",
    "model.fit(pos_train, y1_train)\n",
    "\n",
    "from sklearn. metrics import classification_report\n",
    "\n",
    "y1_pred = model.predict(pos_test)\n",
    "classification_report(pos_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffb66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
